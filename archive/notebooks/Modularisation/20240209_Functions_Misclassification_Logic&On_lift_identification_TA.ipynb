{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f86d9fe2-5682-4930-aac2-5207475f9cd6",
      "metadata": {
        "id": "f86d9fe2-5682-4930-aac2-5207475f9cd6"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d84ea3a2-5469-4073-93b4-bede091e3b68",
      "metadata": {
        "id": "d84ea3a2-5469-4073-93b4-bede091e3b68"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import joblib\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JD7qmFqxTfSV",
        "outputId": "885b0289-6f5f-455d-f961-4868593f90ec"
      },
      "id": "JD7qmFqxTfSV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_95 = pd.read_csv('/content/df_95_labeled_on_lift.csv')\n"
      ],
      "metadata": {
        "id": "_KdhqGwgTf3Y"
      },
      "id": "_KdhqGwgTf3Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " pd.options.mode.copy_on_write = True"
      ],
      "metadata": {
        "id": "f3nkONHJSbBj"
      },
      "id": "f3nkONHJSbBj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function - Misclassification Logic Work"
      ],
      "metadata": {
        "id": "upW5zYxeX4D3"
      },
      "id": "upW5zYxeX4D3"
    },
    {
      "cell_type": "code",
      "source": [
        "# function for masking misclassification (logic)\n",
        "\n",
        "def misclassification_mask(df, column_to_mask, chunk_size, threshold):\n",
        "    \"\"\"\n",
        "    Apply a binary mask to each row in a DataFrame based on the average value of a specified column in chunks.\n",
        "\n",
        "    Parameters:\n",
        "    - df: pandas.DataFrame, the DataFrame to process.\n",
        "    - column_to_mask: str, the name of the column to evaluate.\n",
        "    - chunk_size: int, the number of rows in each chunk.\n",
        "    - threshold: float, the threshold for determining the mask value.\n",
        "\n",
        "    Returns:\n",
        "    - df: pandas.DataFrame, the original DataFrame with an added 'mask' column.\n",
        "    \"\"\"\n",
        "    # Calculate the total number of chunks\n",
        "    total_chunks = len(df) // chunk_size\n",
        "\n",
        "    # Initialize an empty list to store all calculations\n",
        "    all_calculations = []\n",
        "\n",
        "    # Process each chunk\n",
        "    for i in range(total_chunks):\n",
        "        # Fetch a chunk of data\n",
        "        start_index = i * chunk_size\n",
        "        end_index = start_index + chunk_size\n",
        "        data_chunk = df[column_to_mask].iloc[start_index:end_index]\n",
        "\n",
        "        # Process the chunk based on the sum of values\n",
        "        processed_chunk = [1 if sum(data_chunk)/len(data_chunk) >= threshold else 0] * len(data_chunk)\n",
        "        # Append the processed chunk to the list of all calculations\n",
        "        all_calculations += processed_chunk\n",
        "\n",
        "    # Process remainder if any\n",
        "    remainder = len(df) % chunk_size\n",
        "    if remainder > 0:\n",
        "        remainder_data_chunk = df[column_to_mask].iloc[-remainder:]\n",
        "        processed_chunk = [1 if sum(remainder_data_chunk)/len(remainder_data_chunk) >= threshold else 0] * len(remainder_data_chunk)\n",
        "        all_calculations += processed_chunk\n",
        "\n",
        "    # Assign the calculated mask to the DataFrame\n",
        "    df['mask'] = all_calculations\n",
        "    return df.reset_index()\n",
        "\n",
        "# Example usage\n",
        "# Assuming df_option3 is your DataFrame and already defined.\n",
        "# df_option3 = pd.DataFrame(...)\n",
        "# df_with_mask = apply_mask_based_on_threshold(df_option3, 'predicted', 60, 0.3)\n",
        "# print(df_with_mask)\n"
      ],
      "metadata": {
        "id": "rOXjsfV-Zfjm"
      },
      "id": "rOXjsfV-Zfjm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function for defining on-lift identification\n",
        "\n",
        "def on_lift_event_identification(df, column_to_mask, chunk_size, threshold):\n",
        "    \"\"\"\n",
        "    Applies a binary mask to a DataFrame based on the average value of a specified column in chunks,\n",
        "    and logs the start and end index of chunks meeting the threshold.\n",
        "\n",
        "    Parameters:\n",
        "    - df: pandas.DataFrame, the DataFrame to process.\n",
        "    - column_to_mask: str, the column based on whose values the mask will be applied.\n",
        "    - chunk_size: int, the number of rows in each chunk.\n",
        "    - threshold: float, the threshold value for applying the mask.\n",
        "\n",
        "    Returns:\n",
        "    - df: pandas.DataFrame, the DataFrame with an added 'mask' column.\n",
        "    - event_log: dict, log of chunk indices and their start and end positions that meet the threshold.\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the total number of chunks and remainder\n",
        "    total_chunks = len(df) // chunk_size\n",
        "    remainder = len(df) % chunk_size\n",
        "\n",
        "    # Initialize an empty list for calculations and a dictionary for event logging\n",
        "    all_calculations = []\n",
        "    event_log = {}\n",
        "\n",
        "    # Process each chunk\n",
        "    for i in range(total_chunks):\n",
        "        start_index = i * chunk_size\n",
        "        end_index = start_index + chunk_size\n",
        "        data_chunk = df[column_to_mask].iloc[start_index:end_index]\n",
        "\n",
        "        # Process the chunk\n",
        "        if sum(data_chunk) / len(data_chunk) >= threshold:\n",
        "            processed_chunk = [1] * len(data_chunk)\n",
        "            event_log[i] = (start_index, end_index)\n",
        "        else:\n",
        "            processed_chunk = [0] * len(data_chunk)\n",
        "\n",
        "        all_calculations += processed_chunk\n",
        "\n",
        "    # Process remainder\n",
        "    if remainder:\n",
        "        remainder_data_chunk = df[column_to_mask].iloc[-remainder:]\n",
        "        if sum(remainder_data_chunk) / len(remainder_data_chunk) >= threshold:\n",
        "            processed_chunk = [1] * len(remainder_data_chunk)\n",
        "        else:\n",
        "            processed_chunk = [0] * len(remainder_data_chunk)\n",
        "        all_calculations += processed_chunk\n",
        "        # Optionally log remainder chunk if it meets the threshold\n",
        "        if sum(remainder_data_chunk) / len(remainder_data_chunk) >= threshold:\n",
        "            event_log[total_chunks] = (len(df) - remainder, len(df))\n",
        "\n",
        "    # Assign calculated masks to the DataFrame\n",
        "    df['mask'] = all_calculations\n",
        "\n",
        "    ## Storing in a dict instead\n",
        "\n",
        "    continuous_events_dict = {}\n",
        "    event_index = 1\n",
        "\n",
        "    start = None\n",
        "    end = None\n",
        "\n",
        "    for key in sorted(event_log.keys()):\n",
        "        if start is None:\n",
        "            start, end = event_log[key]\n",
        "        elif end == event_log[key][0]:\n",
        "            end = event_log[key][1]\n",
        "        else:\n",
        "            continuous_events_dict[event_index] = (start, end)\n",
        "            event_index += 1\n",
        "            start, end = event_log[key]\n",
        "    # Append the last continuous event\n",
        "    if start is not None and end is not None:\n",
        "        continuous_events_dict[event_index] = (start, end)\n",
        "\n",
        "    print(\"Continuous events as dictionary:\")\n",
        "    for key, value in continuous_events_dict.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "    print('number of continuous events:', len(continuous_events_dict))\n",
        "\n",
        "    df['event']=0\n",
        "    for label in continuous_events_dict:\n",
        "      range_val = [x for x in range(continuous_events_dict[label][0], continuous_events_dict[label][1] + 1)]\n",
        "      df.loc[range_val, 'event'] = label\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "# df_option3 = pd.DataFrame(...) # Assuming df_option3 is your DataFrame\n",
        "# df_on_lift = on_lift_event_identification(df_option3, 'predicted', 60, 0.3)\n",
        "# print(df_on_lift)\n"
      ],
      "metadata": {
        "id": "U-EXjNhvuypq"
      },
      "id": "U-EXjNhvuypq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:consta_ml]",
      "language": "python",
      "name": "conda-env-consta_ml-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "b7ea6e72-4caf-4adf-8e59-859bd33edcff",
        "fn65fYrM5D_r"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}