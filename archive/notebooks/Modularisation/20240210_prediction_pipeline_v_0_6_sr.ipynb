{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f86d9fe2-5682-4930-aac2-5207475f9cd6",
      "metadata": {
        "id": "f86d9fe2-5682-4930-aac2-5207475f9cd6"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "d84ea3a2-5469-4073-93b4-bede091e3b68",
      "metadata": {
        "id": "d84ea3a2-5469-4073-93b4-bede091e3b68"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "#import seaborn as sns\n",
        "import plotly.express as px\n",
        "#import folium\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "import joblib\n",
        "\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BW9She41dwhU",
      "metadata": {
        "id": "BW9She41dwhU"
      },
      "source": [
        "#Configure logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "s3WcxSisdzNS",
      "metadata": {
        "id": "s3WcxSisdzNS"
      },
      "outputs": [],
      "source": [
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f3a61ac-b247-4456-9514-ec198332afb0",
      "metadata": {
        "id": "6f3a61ac-b247-4456-9514-ec198332afb0"
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "df814407-d9a2-498c-bc32-74d5b03f03a0",
      "metadata": {
        "id": "df814407-d9a2-498c-bc32-74d5b03f03a0"
      },
      "outputs": [],
      "source": [
        "def import_data(file_path):\n",
        "    # Read data from the specified file path\n",
        "    df_raw=pd.read_csv(file_path)\n",
        "\n",
        "    # Return the imported DataFrame\n",
        "    return df_raw"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3c1385d-e41b-4ef6-898e-c73c549a1a4d",
      "metadata": {
        "id": "f3c1385d-e41b-4ef6-898e-c73c549a1a4d"
      },
      "source": [
        "# Cleaning Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e54c341-84d6-453c-bdb1-02d8d281d2bc",
      "metadata": {
        "id": "2e54c341-84d6-453c-bdb1-02d8d281d2bc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f9593b0c-4445-49a0-b15e-bbe43d1b0c93",
      "metadata": {
        "id": "f9593b0c-4445-49a0-b15e-bbe43d1b0c93"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "j6rz-hu6jd8n",
      "metadata": {
        "id": "j6rz-hu6jd8n"
      },
      "outputs": [],
      "source": [
        "\n",
        "def add_engineered_features(df, alt_threshold=20, speed_threshold=3, inplace=False):\n",
        "    \"\"\"\n",
        "    Calculate the altitude change, speed change, and course change between consecutive rows and remove outliers.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing the altitude, speed, and course data.\n",
        "        alt_threshold (float): Threshold value for altitude change outlier detection.\n",
        "        speed_threshold (float): Threshold value for speed change outlier detection.\n",
        "        inplace (bool): Whether to modify the original DataFrame or create a copy.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the modified DataFrame and a dictionary with shape information.\n",
        "    \"\"\"\n",
        "    # Check if required columns exist\n",
        "    required_columns = ['Alt(m)', 'Speed(m/s)', 'Course']\n",
        "    if not all(col in df.columns for col in required_columns):\n",
        "        logger.error(\"Required columns not found in DataFrame.\")\n",
        "        return None, {}\n",
        "\n",
        "    # Store the initial DataFrame size\n",
        "    initial_size = len(df)\n",
        "\n",
        "    # Calculate changes\n",
        "    df['Alt(m)_change'] = df['Alt(m)'].diff().fillna(0)\n",
        "    df['Speed(m/s)_change'] = df['Speed(m/s)'].diff().fillna(0)\n",
        "    df['Course_change'] = df['Course'].diff().fillna(0)\n",
        "\n",
        "    # Remove outliers\n",
        "    mask = (df['Alt(m)_change'].abs() <= alt_threshold) & \\\n",
        "           (df['Speed(m/s)_change'].abs() <= speed_threshold)\n",
        "    filtered_df = df[mask] if inplace else df.copy()[mask]\n",
        "\n",
        "    # Reset the index of the filtered DataFrame\n",
        "    filtered_df = filtered_df.reset_index(drop=True)\n",
        "\n",
        "    # Log the shape after outlier removal\n",
        "    logger.info(\"Shape before outlier removal: %d\", initial_size)\n",
        "    logger.info(\"Shape after outlier removal: %d\", len(filtered_df))\n",
        "\n",
        "    return filtered_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "41a38dad-79b0-4543-9240-c1c6cb52ff5a",
      "metadata": {
        "id": "41a38dad-79b0-4543-9240-c1c6cb52ff5a"
      },
      "outputs": [],
      "source": [
        "#updated convert_datetime function\n",
        "def convert_datetime(df, inplace=False):\n",
        "    \"\"\"\n",
        "    Convert the 'Timestamp' column in a DataFrame to datetime format.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing the 'Timestamp' column.\n",
        "        inplace (bool): Whether to modify the original DataFrame or create a copy.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with the 'Timestamp' column converted to datetime format.\n",
        "    \"\"\"\n",
        "    # Check if 'Timestamp' column exists\n",
        "    if 'Timestamp' not in df.columns:\n",
        "        raise ValueError(\"Column 'Timestamp' not found in DataFrame.\")\n",
        "\n",
        "    # Convert 'Timestamp' column to datetime format\n",
        "    if inplace:\n",
        "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='ns')\n",
        "    else:\n",
        "        df = df.copy()\n",
        "        df['Timestamp'] = pd.to_datetime(df['Timestamp'], unit='ns')\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66a92929-2c49-489e-8a57-4934a49d3f2c",
      "metadata": {
        "id": "66a92929-2c49-489e-8a57-4934a49d3f2c"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "8a552e5d-66bf-476c-80c0-96c03222a8ec",
      "metadata": {
        "id": "8a552e5d-66bf-476c-80c0-96c03222a8ec"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def select_features(df):\n",
        "    \"\"\"\n",
        "    Select a subset of features from a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing the features.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame containing only the selected features.\n",
        "    \"\"\"\n",
        "    features_to_use = ['accelX(g)', 'accelY(g)', 'accelZ(g)', 'accelUserX(g)', 'accelUserY(g)',\n",
        "                       'accelUserZ(g)', 'gyroX(rad/s)', 'gyroY(rad/s)', 'gyroZ(rad/s)',\n",
        "                       'Roll(rads)', 'Pitch(rads)', 'Yaw(rads)', 'Lat', 'Long', 'Speed(m/s)',\n",
        "                       'HorizontalAccuracy(m)', 'VerticalAccuracy(m)', 'Course', 'calMagX(µT)',\n",
        "                       'calMagY(µT)', 'calMagZ(µT)', 'Alt(m)_change',\n",
        "                       'Speed(m/s)_change', 'Course_change']\n",
        "\n",
        "    # Check if all features exist in the DataFrame\n",
        "    missing_features = [feature for feature in features_to_use if feature not in df.columns]\n",
        "    if missing_features:\n",
        "        raise ValueError(f\"Features not found in DataFrame: {missing_features}\")\n",
        "\n",
        "    # Select the features\n",
        "    X = df[features_to_use]\n",
        "\n",
        "    return X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "947c5bbd-d2fc-48a5-9d7c-9f121bafb39c",
      "metadata": {
        "id": "947c5bbd-d2fc-48a5-9d7c-9f121bafb39c"
      },
      "outputs": [],
      "source": [
        "def load_model(file_path_to_model):\n",
        "\n",
        "    # Load the saved model\n",
        "    return joblib.load(file_path_to_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "701b7d08-1e8d-4b11-9e92-ffe53f78b998",
      "metadata": {
        "id": "701b7d08-1e8d-4b11-9e92-ffe53f78b998"
      },
      "outputs": [],
      "source": [
        "def show_hyperparameters(model):\n",
        "    # show hyperparameters\n",
        "    return model.get_params()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "2e228699-a2d5-45a3-bcfb-96754318aaac",
      "metadata": {
        "id": "2e228699-a2d5-45a3-bcfb-96754318aaac"
      },
      "outputs": [],
      "source": [
        "def predict_on_features(model, df, features):\n",
        "\n",
        "    predictions=model.predict(features)\n",
        "\n",
        "    df['predicted']=predictions\n",
        "\n",
        "    return df.reset_index()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcb9638d-7865-4beb-a3b9-555b1dd0d79a",
      "metadata": {
        "id": "bcb9638d-7865-4beb-a3b9-555b1dd0d79a"
      },
      "source": [
        "# Visualisation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55dbba4c-3269-48a5-b352-19b43819a833",
      "metadata": {
        "id": "55dbba4c-3269-48a5-b352-19b43819a833"
      },
      "source": [
        "### Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "abeca948-e26e-46c6-ba0b-7964ff9b050d",
      "metadata": {
        "id": "abeca948-e26e-46c6-ba0b-7964ff9b050d"
      },
      "outputs": [],
      "source": [
        "def plot_prediction(df, target_column='predicted', cmap=None):\n",
        "    # Define the plot title based on the target column\n",
        "    if target_column == 'on_lift':\n",
        "        plot_title = 'Predictions'\n",
        "    elif target_column == 'mask':\n",
        "        plot_title = 'Clean Predictions with mask'\n",
        "    elif target_column == 'event':\n",
        "        plot_title = 'Lift Events'\n",
        "    else:\n",
        "        plot_title = 'Predictions'\n",
        "\n",
        "\n",
        "    # Use the passed colormap if available, otherwise use the default\n",
        "    if cmap is None:\n",
        "        dark2_cmap = ListedColormap(plt.cm.Dark2(range(8)))\n",
        "        cmap = {str(idx): color for idx, color in enumerate(dark2_cmap.colors)}\n",
        "\n",
        "\n",
        "    # Check if 'Timestamp' column exists and is in datetime format\n",
        "    if 'Timestamp' in df.columns and pd.api.types.is_datetime64_any_dtype(df['Timestamp']):\n",
        "        # Create a scatter plot for Altitude over Time, colored by target_column with an accessible color scheme\n",
        "        fig = px.scatter(df, x='Timestamp',\n",
        "                         y='Alt(m)', color=target_column,\n",
        "                         labels={'Alt(m)': 'Altitude (m)'},\n",
        "                         title=plot_title,\n",
        "                         color_discrete_map=cmap)\n",
        "\n",
        "        fig.update_traces(marker=dict(size=8),\n",
        "                          selector=dict(mode='markers'))\n",
        "\n",
        "        # Customize the legend\n",
        "        fig.update_layout(\n",
        "            legend_title_text='Status',\n",
        "            width=1000,\n",
        "            height=600\n",
        "        )\n",
        "\n",
        "        # Update legend labels based on target_column\n",
        "        if target_column == 'on_lift':\n",
        "            fig.for_each_trace(lambda trace: trace.update(name='Not on the lift' if trace.name == '0' else 'On the lift'))\n",
        "        # Add more conditions if there are different classes for other target_columns\n",
        "\n",
        "        # Show the plot\n",
        "        fig.show()\n",
        "    else:\n",
        "        print(\"Warning: DataFrame's 'Timestamp' column is not in datetime format and must be converted first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "68e453f9-4a40-473f-bfa2-139e88a64544",
      "metadata": {
        "id": "68e453f9-4a40-473f-bfa2-139e88a64544"
      },
      "outputs": [],
      "source": [
        "def plot_total_alt_over_time(df, plot_title='Total Tracked Altitude Over Time'):\n",
        "\n",
        "    # Create a line plot using Plotly\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Add a trace for altitude over time\n",
        "    fig.add_trace(go.Scatter(x=df['Timestamp'],\n",
        "                             y=df['Alt(m)'],\n",
        "                             mode='lines',\n",
        "                             name='Altitude'))\n",
        "\n",
        "    # Update layout\n",
        "    fig.update_layout(title=plot_title,\n",
        "                      xaxis_title='Timestamp',\n",
        "                      yaxis_title='Altitude (m)')\n",
        "\n",
        "    # Show plot\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dac24adf-d97e-45db-b037-20d38bee2eb1",
      "metadata": {
        "id": "dac24adf-d97e-45db-b037-20d38bee2eb1"
      },
      "source": [
        "### Mapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "D4Nf1TYacetv",
      "metadata": {
        "id": "D4Nf1TYacetv"
      },
      "outputs": [],
      "source": [
        "#Map all tracked movement based on lat and long of GPS data\n",
        "\n",
        "def map_tracked_movement(df, zoom_start=12):\n",
        "    # Create a map centered on the mean latitude and longitude\n",
        "    map_center = [df['Lat'].mean(), df['Long'].mean()]\n",
        "    movement_on_map = folium.Map(location=map_center, zoom_start=zoom_start)\n",
        "\n",
        "    # Add CircleMarkers for each data point\n",
        "    for index, row in df.iterrows():\n",
        "        folium.CircleMarker(location=[row['Lat'], row['Long']], radius=5, color='blue', fill=True, fill_color='blue').add_to(movement_on_map)\n",
        "\n",
        "    # Display the map\n",
        "    return movement_on_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "g5f0hyzOTmqc",
      "metadata": {
        "id": "g5f0hyzOTmqc"
      },
      "outputs": [],
      "source": [
        "#Map lifts rides in red and all the other movement in blue\n",
        "\n",
        "def map_lifts_and_other_movement(df, column='on_lift', zoom_start=15):\n",
        "    # Create a map centered on the mean latitude and longitude\n",
        "    map_center = [df['Lat'].mean(), df['Long'].mean()]\n",
        "    tracking_map = folium.Map(location=map_center, zoom_start=zoom_start)\n",
        "\n",
        "    # Plot data points with on_lift type\n",
        "    on_lift = df[df[column] == 1]\n",
        "    for _, row in on_lift.iterrows():\n",
        "        folium.CircleMarker(location=[row['Lat'], row['Long']], radius=5, color='red', fill=True, fill_color='red', tooltip=str(row['Timestamp'])).add_to(tracking_map)\n",
        "\n",
        "    # Plot data points with not_on_lift  types\n",
        "    not_on_lift = df[df[column] != 1]\n",
        "    for _, row in not_on_lift.iterrows():\n",
        "        folium.CircleMarker(location=[row['Lat'], row['Long']], radius=5, color='blue', fill=True, fill_color='blue', tooltip=str(row['Timestamp'])).add_to(tracking_map)\n",
        "\n",
        "    # Return the map object\n",
        "    return tracking_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "jq4VlnhiTpdA",
      "metadata": {
        "id": "jq4VlnhiTpdA"
      },
      "outputs": [],
      "source": [
        "#Map only lifts rides\n",
        "\n",
        "def map_lift_rides(df, column='on_lift', zoom_start=15):\n",
        "    # Create a map centered on the mean latitude and longitude\n",
        "    map_center = [df['Lat'].mean(), df['Long'].mean()]\n",
        "    lift_map = folium.Map(location=map_center, zoom_start=zoom_start)\n",
        "\n",
        "    # Plot data points with on_lift type\n",
        "    on_lift = df[df[column] == 1]\n",
        "    for _, row in on_lift.iterrows():\n",
        "        folium.CircleMarker(location=[row['Lat'],\n",
        "                                      row['Long']],\n",
        "                                      radius=5,\n",
        "                                      color='red',\n",
        "                                      fill=True,\n",
        "                                      fill_color='red',\n",
        "                                      tooltip=str(row['Timestamp'])).add_to(lift_map)\n",
        "\n",
        "    # Return the map object\n",
        "    return lift_map"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c51d3d13-daa5-4527-afc9-d4cdce5d6bcb",
      "metadata": {
        "id": "c51d3d13-daa5-4527-afc9-d4cdce5d6bcb"
      },
      "source": [
        "# Post-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "kM-nXkymQBHL",
      "metadata": {
        "id": "kM-nXkymQBHL"
      },
      "outputs": [],
      "source": [
        "### updated misclassification mask v0.2\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def generate_misclassification_mask(df, column_to_mask='predicted', chunk_size=60, threshold=0.3):\n",
        "    \"\"\"\n",
        "    Apply a binary mask to each row in a DataFrame based on the average value of a specified column in chunks.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing the data.\n",
        "        column_to_mask (str): Name of the column to calculate the mean and apply the mask.\n",
        "        chunk_size (int): Size of the chunks to divide the DataFrame into.\n",
        "        threshold (float): Threshold value for determining the mask value.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the updated DataFrame with the mask applied and the event log.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if the 'mask' column already exists\n",
        "    if 'mask' in df.columns:\n",
        "        raise ValueError(\"The 'mask' column already exists in the DataFrame.\")\n",
        "\n",
        "    # Initialize the event log\n",
        "    event_log = {}\n",
        "\n",
        "    # Calculate the total number of chunks\n",
        "    total_chunks = len(df) // chunk_size\n",
        "    remainder = len(df) % chunk_size\n",
        "\n",
        "    # Process each chunk\n",
        "    for i in range(total_chunks):\n",
        "        start_index = i * chunk_size\n",
        "        end_index = start_index + chunk_size\n",
        "\n",
        "        # Calculate the mean of the chunk and create the mask\n",
        "        mean_value = df[column_to_mask].iloc[start_index:end_index].mean()\n",
        "        mask_value =  1 if mean_value >= threshold else  0\n",
        "\n",
        "        # Update the DataFrame with the mask value\n",
        "        df.loc[start_index:end_index, 'mask'] = mask_value\n",
        "\n",
        "        # Record the event log\n",
        "        event_log[i] = (start_index, end_index, mask_value)\n",
        "\n",
        "    # Process the remainder if any\n",
        "    if remainder >  0:\n",
        "        start_index = total_chunks * chunk_size\n",
        "        end_index = len(df)\n",
        "\n",
        "        # Calculate the mean of the remainder and create the mask\n",
        "        mean_value = df[column_to_mask].iloc[start_index:end_index].mean()\n",
        "        mask_value =  1 if mean_value >= threshold else  0\n",
        "\n",
        "        # Update the DataFrame with the mask value\n",
        "        df.loc[start_index:end_index, 'mask'] = mask_value\n",
        "\n",
        "        # Record the event log for the remainder\n",
        "        event_log[total_chunks] = (start_index, end_index, mask_value)\n",
        "\n",
        "    # Return the updated DataFrame and the event log\n",
        "    return df, event_log\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "iATOGsydTvfX",
      "metadata": {
        "id": "iATOGsydTvfX"
      },
      "outputs": [],
      "source": [
        "# Updated Function for defining on-lift identification v0.2\n",
        "\n",
        "def on_lift_event_identification(df, event_log):\n",
        "    \"\"\"\n",
        "    Identify continuous events in a DataFrame based on an event log and assign a unique label to each event.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing the data.\n",
        "        event_log (dict): Event log generated by the generate_misclassification_mask function.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The updated DataFrame with a new 'event' column indicating the event label for each row.\n",
        "    \"\"\"\n",
        "    # Validate the event log\n",
        "    if not isinstance(event_log, dict) or not all(isinstance(v, tuple) and len(v) ==  3 for v in event_log.values()):\n",
        "        raise ValueError(\"Invalid event log format.\")\n",
        "\n",
        "    continuous_events_dict = {}\n",
        "    event_index = 1\n",
        "\n",
        "    start = None\n",
        "    end = None\n",
        "\n",
        "    for key in sorted(event_log.keys()):\n",
        "        if event_log[key][2] > 0:\n",
        "          if start is None:\n",
        "              start = event_log[key][0]\n",
        "              end = event_log[key][1]\n",
        "          elif end == event_log[key][0]:\n",
        "              end = event_log[key][1]\n",
        "          else:\n",
        "              continuous_events_dict[event_index] = (start, end)\n",
        "              event_index += 1\n",
        "              start, end, _ = event_log[key]\n",
        "\n",
        "          # Append the last continuous event\n",
        "        if start is not None and end is not None:\n",
        "              continuous_events_dict[event_index] = (start, end)\n",
        "              event_index +=  1\n",
        "              start = None\n",
        "              end = None\n",
        "\n",
        "    # Assign event labels to the DataFrame\n",
        "    df['event'] = 0\n",
        "    for label in continuous_events_dict:\n",
        "      range_val = [x for x in range(continuous_events_dict[label][0], continuous_events_dict[label][1] + 1)]\n",
        "      df.loc[range_val, 'event'] = label\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9c4b648-ac67-4a77-a810-2806845ae177",
      "metadata": {
        "id": "c9c4b648-ac67-4a77-a810-2806845ae177"
      },
      "source": [
        "# Prediction steps in one function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "0e5eebf6-bc63-4748-b67d-b5c085b6bf87",
      "metadata": {
        "id": "0e5eebf6-bc63-4748-b67d-b5c085b6bf87"
      },
      "outputs": [],
      "source": [
        "# use this to predict on a csv that already has all data points\n",
        "def predict_on_data(path_to_csv_file, file_path_to_model):\n",
        "\n",
        "    # Load the data\n",
        "    df = pd.read_csv(path_to_csv_file)\n",
        "\n",
        "    # Preprocess and feature engineering\n",
        "    df = add_engineered_features(df)\n",
        "    df = convert_datetime(df)\n",
        "\n",
        "    # Feature selection\n",
        "    features = select_features(df)\n",
        "\n",
        "    # Load the model\n",
        "    rfc = joblib.load(file_path_to_model)\n",
        "\n",
        "    # Make predictions\n",
        "    df = predict_on_features(rfc, df, features)\n",
        "\n",
        "    # Update preidctions with mask\n",
        "    df, event_log = generate_misclassification_mask(df)\n",
        "\n",
        "    #Generate on lift event assignments\n",
        "    df = on_lift_event_identification(df, event_log)\n",
        "\n",
        "    # Plot predictions\n",
        "    plot_prediction(df, target_column='mask')\n",
        "    plot_prediction(df, target_column='event')\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88cab3ca-e76f-4221-9358-98440b0c52b1",
      "metadata": {
        "id": "88cab3ca-e76f-4221-9358-98440b0c52b1"
      },
      "source": [
        "# \"Real time\" prediction simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0244f148-de3a-483a-833f-8007c0c79e4c",
      "metadata": {
        "id": "0244f148-de3a-483a-833f-8007c0c79e4c"
      },
      "source": [
        "fetch_and_process_data_beta_v0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "6db41664-08fa-4323-b4b3-bffebef12a10",
      "metadata": {
        "id": "6db41664-08fa-4323-b4b3-bffebef12a10"
      },
      "outputs": [],
      "source": [
        "def real_time_prediction_beta(path_to_csv_file, chunk_size=60, wait_time=2):\n",
        "\n",
        "    # Load the dataset\n",
        "    df_input = pd.read_csv(path_to_csv_file)\n",
        "\n",
        "    # Calculate the total number of chunks\n",
        "    total_chunks = len(df_input) // chunk_size\n",
        "\n",
        "    # Initialize an empty list to store all calculations\n",
        "    all_calculations = pd.DataFrame()\n",
        "\n",
        "    fig = px.scatter()\n",
        "\n",
        "    for i in range(total_chunks):\n",
        "        # Fetch a chunk of 60 observations\n",
        "        start_index = i * chunk_size\n",
        "        end_index = start_index + chunk_size\n",
        "        data_chunk = df_input.iloc[start_index:end_index]\n",
        "\n",
        "        # Append the processed chunk to the list of all calculations\n",
        "        all_calculations = pd.concat([all_calculations, data_chunk], ignore_index=True)\n",
        "\n",
        "        # Preprocess and feature engineering\n",
        "        df = add_engineered_features(all_calculations)\n",
        "        df = convert_datetime(df)\n",
        "\n",
        "        # print(df.shape)\n",
        "        # Feature selection\n",
        "        features = select_features(df)\n",
        "\n",
        "        # # Make predictions\n",
        "        df = predict_on_features(rfc, df, features)\n",
        "        df, event_log = generate_misclassification_mask(df)\n",
        "\n",
        "        plot_prediction(df, target_column='mask')\n",
        "\n",
        "        # Wait for declared wait_time before processing the next chunk\n",
        "        time.sleep(wait_time)\n",
        "\n",
        "    df = on_lift_event_identification(df, event_log)\n",
        "    plot_prediction(df, target_column='event')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac981819-64c4-44bc-b850-4e92cea02dc2",
      "metadata": {
        "id": "ac981819-64c4-44bc-b850-4e92cea02dc2"
      },
      "source": [
        "# To do before going for one of the options\n",
        "\n",
        "Make sure that you specify the paths and other variables needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "a3a793a0-54f4-4b5f-ab41-1514eadf5a92",
      "metadata": {
        "id": "a3a793a0-54f4-4b5f-ab41-1514eadf5a92"
      },
      "outputs": [],
      "source": [
        "# These are the default values used in the function fetch_and_process_data, change if needed\n",
        "chunk_size=60\n",
        "wait_time=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "JL53OJX5HRjv",
      "metadata": {
        "id": "JL53OJX5HRjv"
      },
      "outputs": [],
      "source": [
        "path_to_csv_file='../../data/processed/df_310_labeled_on_lift_v4.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "W_t0KaoyHbta",
      "metadata": {
        "id": "W_t0KaoyHbta"
      },
      "outputs": [],
      "source": [
        "file_path_to_model = '../../models/rf_v_0.4.pkl'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b25605b-3302-4f94-a9b4-08f4ab00ce28",
      "metadata": {
        "id": "1b25605b-3302-4f94-a9b4-08f4ab00ce28"
      },
      "source": [
        "# Option 1: 'Real time' prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "ae877034-f5d6-4452-8b45-a1e7f3a66d2e",
      "metadata": {
        "id": "ae877034-f5d6-4452-8b45-a1e7f3a66d2e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-11 17:14:23,388 - INFO - Shape before outlier removal: 60\n",
            "2024-02-11 17:14:23,389 - INFO - Shape after outlier removal: 59\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[83], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # Call this function to simulate prediction in 'real time'\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_option1 \u001b[38;5;241m=\u001b[39m \u001b[43mreal_time_prediction_beta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_csv_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mwait_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[79], line 35\u001b[0m, in \u001b[0;36mreal_time_prediction_beta\u001b[1;34m(path_to_csv_file, chunk_size, wait_time)\u001b[0m\n\u001b[0;32m     32\u001b[0m df \u001b[38;5;241m=\u001b[39m predict_on_features(rfc, df, features)\n\u001b[0;32m     33\u001b[0m df, event_log \u001b[38;5;241m=\u001b[39m generate_misclassification_mask(df)\n\u001b[1;32m---> 35\u001b[0m \u001b[43mplot_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmask\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Wait for declared wait_time before processing the next chunk\u001b[39;00m\n\u001b[0;32m     38\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(wait_time)\n",
            "Cell \u001b[1;32mIn[71], line 44\u001b[0m, in \u001b[0;36mplot_prediction\u001b[1;34m(df, target_column, cmap)\u001b[0m\n\u001b[0;32m     40\u001b[0m         fig\u001b[38;5;241m.\u001b[39mfor_each_trace(\u001b[38;5;28;01mlambda\u001b[39;00m trace: trace\u001b[38;5;241m.\u001b[39mupdate(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot on the lift\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOn the lift\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# Add more conditions if there are different classes for other target_columns\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Show the plot\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: DataFrame\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m column is not in datetime format and must be converted first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\plotly\\basedatatypes.py:3410\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3377\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3378\u001b[0m \u001b[38;5;124;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[0;32m   3379\u001b[0m \u001b[38;5;124;03mspecified by the renderer argument\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3406\u001b[0m \u001b[38;5;124;03mNone\u001b[39;00m\n\u001b[0;32m   3407\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3408\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpio\u001b[39;00m\n\u001b[1;32m-> 3410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\sebas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\plotly\\io\\_renderers.py:394\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         )\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m Version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m4.2.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 394\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    395\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    396\u001b[0m         )\n\u001b[0;32m    398\u001b[0m     ipython_display\u001b[38;5;241m.\u001b[39mdisplay(bundle, raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# external renderers\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
          ]
        }
      ],
      "source": [
        "# # Call this function to simulate prediction in 'real time'\n",
        "df_option1 = real_time_prediction_beta(path_to_csv_file,\n",
        "                       chunk_size=60,\n",
        "                       wait_time=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1dbf208b-f3d5-4b72-86cc-5b64f77a105a",
      "metadata": {
        "id": "1dbf208b-f3d5-4b72-86cc-5b64f77a105a"
      },
      "source": [
        "# Option 2: One step to prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b98e6e7c-6564-43b3-8cca-56dfbdfa7d23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b98e6e7c-6564-43b3-8cca-56dfbdfa7d23",
        "outputId": "28c340f7-e214-4222-bd3e-54bab269173d"
      },
      "outputs": [],
      "source": [
        "df_option2 = predict_on_data(path_to_csv_file, file_path_to_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80cc31ad-4419-4988-9019-ec6562a4d8c0",
      "metadata": {
        "id": "80cc31ad-4419-4988-9019-ec6562a4d8c0",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "# Option 3: Go through everything step by step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2636c012-54fc-4a05-b28c-05fb4ac40401",
      "metadata": {
        "id": "2636c012-54fc-4a05-b28c-05fb4ac40401"
      },
      "outputs": [],
      "source": [
        "df_option3=import_data(path_to_csv_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "a100ea19-b5ef-4c69-a5a3-e4041ce7ed5e",
      "metadata": {
        "id": "a100ea19-b5ef-4c69-a5a3-e4041ce7ed5e",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-11 16:31:42,907 - INFO - Shape before outlier removal: 18577\n",
            "2024-02-11 16:31:42,909 - INFO - Shape after outlier removal: 18438\n"
          ]
        }
      ],
      "source": [
        "df_option3=add_engineered_features(df_option3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "72ef8efa-07da-44e9-9923-af8fdd6484e6",
      "metadata": {
        "id": "72ef8efa-07da-44e9-9923-af8fdd6484e6"
      },
      "outputs": [],
      "source": [
        "df_option3=convert_datetime(df_option3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "2036a379-053e-4101-ab29-bed37ee94470",
      "metadata": {
        "id": "2036a379-053e-4101-ab29-bed37ee94470"
      },
      "outputs": [],
      "source": [
        "features=select_features(df_option3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "cb4ba9fe-13fb-47f5-91a3-d01cbdfb7296",
      "metadata": {
        "id": "cb4ba9fe-13fb-47f5-91a3-d01cbdfb7296"
      },
      "outputs": [],
      "source": [
        "rfc=load_model(file_path_to_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "8d227bce-0840-44a5-a238-fb7ff6d56ad0",
      "metadata": {
        "id": "8d227bce-0840-44a5-a238-fb7ff6d56ad0"
      },
      "outputs": [],
      "source": [
        "df_option3=predict_on_features(rfc, df_option3, features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "UaDc9MtiRyAG",
      "metadata": {
        "id": "UaDc9MtiRyAG"
      },
      "outputs": [],
      "source": [
        "df_option3, event_log = generate_misclassification_mask(df_option3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "1Oz0-6zBSLio",
      "metadata": {
        "id": "1Oz0-6zBSLio"
      },
      "outputs": [],
      "source": [
        "df_option3 = on_lift_event_identification(df_option3, event_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x-FC7XGkvsbA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "x-FC7XGkvsbA",
        "outputId": "901fda64-f1f7-4131-dd24-77c99c5f065b"
      },
      "outputs": [],
      "source": [
        "plot_prediction(df_option3, target_column='predicted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d727cc67-ae75-437c-bb9b-ca9d769c1fb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "d727cc67-ae75-437c-bb9b-ca9d769c1fb9",
        "outputId": "11889013-ad16-44c0-ab6e-780149c55267"
      },
      "outputs": [],
      "source": [
        "plot_prediction(df_option3, target_column='mask')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G0ujGecGWHwO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "G0ujGecGWHwO",
        "outputId": "2bc7fb9c-dc9e-451c-ccb7-4638853a7964"
      },
      "outputs": [],
      "source": [
        "plot_prediction(df_option3, target_column='event')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6132b1b8",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
